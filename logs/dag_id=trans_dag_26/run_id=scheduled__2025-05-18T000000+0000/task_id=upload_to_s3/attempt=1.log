[2025-07-21T22:53:12.695+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: trans_dag_26.upload_to_s3 scheduled__2025-05-18T00:00:00+00:00 [queued]>
[2025-07-21T22:53:12.711+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: trans_dag_26.upload_to_s3 scheduled__2025-05-18T00:00:00+00:00 [queued]>
[2025-07-21T22:53:12.714+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2025-07-21T22:53:12.715+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 2
[2025-07-21T22:53:12.716+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2025-07-21T22:53:12.737+0000] {taskinstance.py:1383} INFO - Executing <Task(_PythonDecoratedOperator): upload_to_s3> on 2025-05-18 00:00:00+00:00
[2025-07-21T22:53:12.759+0000] {standard_task_runner.py:55} INFO - Started process 88793 to run task
[2025-07-21T22:53:12.768+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'trans_dag_26', 'upload_to_s3', 'scheduled__2025-05-18T00:00:00+00:00', '--job-id', '11548', '--raw', '--subdir', 'DAGS_FOLDER/trans_dag.py', '--cfg-path', '/tmp/tmpgztsy8q1']
[2025-07-21T22:53:12.772+0000] {standard_task_runner.py:83} INFO - Job 11548: Subtask upload_to_s3
[2025-07-21T22:53:12.961+0000] {task_command.py:376} INFO - Running <TaskInstance: trans_dag_26.upload_to_s3 scheduled__2025-05-18T00:00:00+00:00 [running]> on host 77e451e90f2e
[2025-07-21T22:53:13.159+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=trans_dag_26
AIRFLOW_CTX_TASK_ID=upload_to_s3
AIRFLOW_CTX_EXECUTION_DATE=2025-05-18T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-05-18T00:00:00+00:00
[2025-07-21T22:53:13.183+0000] {base.py:71} INFO - Using connection ID 'aws-connect' for task execution.
[2025-07-21T22:53:13.197+0000] {connection_wrapper.py:303} INFO - AWS Connection (conn_id='aws-connect', conn_type='aws') credentials retrieved from login and password.
[2025-07-21T22:56:16.515+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/transfer.py", line 288, in upload_file
    future.result()
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/futures.py", line 103, in result
    return self._coordinator.result()
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/futures.py", line 266, in result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/tasks.py", line 139, in __call__
    return self._execute_main(kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/tasks.py", line 162, in _execute_main
    return_value = self._main(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/s3transfer/upload.py", line 793, in _main
    **extra_args,
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 508, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/botocore/client.py", line 915, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (RequestTimeout) when calling the UploadPart operation (reached max retries: 4): Your socket connection to the server was not read from or written to within the timeout period. Idle connections will be closed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 188, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 193, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/trans_dag.py", line 89, in upload_to_s3
    s3_hook.load_file(filename=file_path_s3, key=key, bucket_name=bucket_name, replace=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 64, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 92, in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/amazon/aws/hooks/s3.py", line 649, in load_file
    client.upload_file(filename, bucket_name, key, ExtraArgs=extra_args, Config=self.transfer_config)
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/inject.py", line 148, in upload_file
    callback=Callback,
  File "/home/airflow/.local/lib/python3.7/site-packages/boto3/s3/transfer.py", line 296, in upload_file
    filename, '/'.join([bucket, key]), e
boto3.exceptions.S3UploadFailedError: Failed to upload /tmp/transformed.csv to imani-***-data/transformed/transformed.csv: An error occurred (RequestTimeout) when calling the UploadPart operation (reached max retries: 4): Your socket connection to the server was not read from or written to within the timeout period. Idle connections will be closed.
[2025-07-21T22:56:16.540+0000] {taskinstance.py:1406} INFO - Marking task as UP_FOR_RETRY. dag_id=trans_dag_26, task_id=upload_to_s3, execution_date=20250518T000000, start_date=20250721T225312, end_date=20250721T225616
[2025-07-21T22:56:16.562+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 11548 for task upload_to_s3 (Failed to upload /tmp/transformed.csv to imani-***-data/transformed/transformed.csv: An error occurred (RequestTimeout) when calling the UploadPart operation (reached max retries: 4): Your socket connection to the server was not read from or written to within the timeout period. Idle connections will be closed.; 88793)
[2025-07-21T22:56:16.598+0000] {local_task_job.py:164} INFO - Task exited with return code 1
[2025-07-21T22:56:16.623+0000] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
